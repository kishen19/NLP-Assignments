{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis of Hin-Eng mixed tweets\n",
    "\n",
    "Dataset: <a href=\"https://drive.google.com/file/d/1qpXAWrbNzL_TRK5OAYgXp6y-KAg0T11h/view?usp=sharing\" >link</a>\n",
    "\n",
    "## Methodology:\n",
    "Github: <a href=\"\">link</a>\n",
    "\n",
    "For this task, I propose the following novel architecture based on SVM. As we know, SVMs are one of the best for classification based tasks. But, as these are Hindi-English mixed tweets, some pre-processing has to be done. So, my method can be described in three phases:\n",
    "\n",
    "<ol>\n",
    "    <li> <b>Phase I (Pre-processing):</b> First, I clean the unwanted text from the tweets (like the ones with labels \"O\", links, etc.). Next, on keen observation, I noticed that the labels of \"Hin\" and \"Eng\" were not proper in most of the tweets, especially the ones tagged \"Hin\". So, I followed the following procedure:\n",
    "        <ul>\n",
    "            <li> Check if the word exists in Wordnet, if yes just return, else keep it for further processing.</li>\n",
    "            <li> Check if the word is a bad word using <a href=\"https://github.com/precog-iiitd/mind-your-language-aaai\">this</a> dictionary, if yes, translate, else keep for further processing </li>\n",
    "            <li> Finally, translate this word using Google's Cloud Translate API</li>\n",
    "        </ul>\n",
    "    </li> \n",
    "    <li> <b>Phase II:</b> In the first phase, the aim is to classify the tweets if they are of neutral stance or non-neutral stane. For that, I used the Weighted MPQA Subjectivity-Polarity Classification. Based on the subjectivity score, if the cumulative score is either $\\lt$ 2 or $\\gt$ 2, they are classified as non-neutral, else neutral. Also, if there is an adjective in a tweet, it generally implies subjectivity. Hene, using Wordnet based potential adjective recognition I classify between non-neutral and neutral.\n",
    "    </li>\n",
    "    <li> <b> Phase III:</b> In this phase, I classify between positive and negative stances. For that, I use Sentiwordnet to fetch positive and negative scores of the words, and then consider cumulative scores. With this as feature, I use CountVectorizer (One Hot Encodings) on the tweets and concatenate it to form the feature vector. Then I use this as input to the SVM model.\n",
    "    </li>\n",
    "</ol>\n",
    "\n",
    "[**Note:** I tried tf-idf vectors as well as Glove embeddings, but among them, one hot encoding had highest accuracy.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import csv\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from nltk import sent_tokenize, word_tokenize, pos_tag\n",
    "from nltk import ngrams,bigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fetching MPQA Subjectivity Lexicon**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicon = {}\n",
    "with open('./MPQA/lexicon_easy.csv',\"r\") as csvfile:\n",
    "    data = csv.reader(csvfile)\n",
    "    for row in data:\n",
    "        row[1] = int(row[1])\n",
    "        row[2] = int(row[2])\n",
    "        lexicon[row[0]] = {}\n",
    "        lexicon[row[0]]['subj'] = row[1]\n",
    "        lexicon[row[0]]['sent'] = row[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Utility functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function which returns subjectivity score of a given tweet. See description for scores.\n",
    "def mpqa_subj(tweet):\n",
    "    feat = 0\n",
    "    score = 0\n",
    "    tokens = word_tokenize(tweet)\n",
    "    for token in tokens: \n",
    "        if token in lexicon:\n",
    "            score+= lexicon[token]['subj']\n",
    "    if score > 2 or score < -2:\n",
    "        feat = 1\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function which returns presence of adjectives\n",
    "def pot_adj(tweet):\n",
    "    feat = 0\n",
    "    tokens = word_tokenize(tweet)\n",
    "    for token in tokens:\n",
    "        synsets = wn.synsets(token)\n",
    "        for s in synsets:\n",
    "            if s.pos() == 'a':\n",
    "                feat = 1\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Function to convert between the PennTreebank tags to simple Wordnet tags\n",
    "def penn_to_wn(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wn.ADJ\n",
    "    elif tag.startswith('N'):\n",
    "        return wn.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wn.ADV\n",
    "    elif tag.startswith('V'):\n",
    "        return wn.VERB\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function which returns sentiment scores [SentiWordnet]\n",
    "def swn_polarity(tweet):\n",
    "    sentiment = 0.0\n",
    "    tokens_count = 0\n",
    "    tagged_sentence = pos_tag(word_tokenize(tweet))\n",
    "    for word, tag in tagged_sentence:\n",
    "        wn_tag = penn_to_wn(tag)\n",
    "        \n",
    "        if wn_tag not in (wn.NOUN, wn.ADJ, wn.ADV):\n",
    "            continue\n",
    "        lemma = lemmatizer.lemmatize(word, pos=wn_tag)\n",
    "        \n",
    "        if not lemma:\n",
    "            continue\n",
    "        synsets = wn.synsets(lemma, pos=wn_tag)\n",
    "        \n",
    "        if not synsets:\n",
    "            continue\n",
    "        synset = synsets[0]\n",
    "        swn_synset = swn.senti_synset(synset.name())\n",
    "        \n",
    "        if swn_synset.pos_score() - swn_synset.neg_score()>0:\n",
    "            sentiment+=1\n",
    "        elif swn_synset.pos_score() - swn_synset.neg_score()<0:\n",
    "            sentiment+=-1\n",
    "        tokens_count += 1\n",
    "    \n",
    "    if not tokens_count:\n",
    "        return 0\n",
    "    \n",
    "    return sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function which returns sentiment polarity based on sentiment scores\n",
    "def sentiword_mpqa_sentiment(tweet):\n",
    "    feat = [0,0]\n",
    "    feat[0] = swn_polarity(tweet)\n",
    "    tokens = word_tokenize(tweet)\n",
    "    for token in tokens:\n",
    "        if token in lexicon:\n",
    "            feat[1]+= lexicon[token]['sent']\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for prediction\n",
    "def predict(clf1,clf2,x):\n",
    "    ph1 = [x[0]]\n",
    "    ph2 = [x[1]]\n",
    "    p1 = clf1.predict(ph1)\n",
    "    if p1[0] == 1:\n",
    "        return 2\n",
    "    else:\n",
    "        p2 = clf2.predict(ph2)\n",
    "        if p2[0] == 1:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for calculating scores\n",
    "def score(y_true,y_pred):\n",
    "    fav = [0,0,0]\n",
    "    ag = [0,0,0]\n",
    "    tot = [fav,ag]\n",
    "    corr = 0\n",
    "    for y_t,y_p in zip(y_true,y_pred):\n",
    "        if y_t < 2:\n",
    "            tot[y_t][2]+=1\n",
    "        if y_p < 2:\n",
    "            tot[y_p][1]+=1\n",
    "        if y_t == y_p and y_t < 2:\n",
    "            tot[y_t][0]+=1\n",
    "        if y_t == y_p:\n",
    "            corr+=1\n",
    "\n",
    "        r0 = tot[0][0]/(tot[0][2]+1e-5)\n",
    "        p0 = tot[0][0]/(tot[0][1]+1e-5)\n",
    "        r1 = tot[1][0]/(tot[1][2]+1e-5)\n",
    "        p1 = tot[1][0]/(tot[1][1]+1e-5)\n",
    "        f0 = 2*r0*p0/(r0+p0+1e-5)\n",
    "        f1 = 2*r1*p1/(r1+p1+1e-5)\n",
    "        \n",
    "        f_avg = (f0+f1)/2\n",
    "    return tot,f_avg, corr/len(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetching data and preparing Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "features = {}\n",
    "train_file = \"./data1/train_modified.txt\"\n",
    "test_file = \"./data1/test_modified.txt\"\n",
    "#Set up the TF-IDF Vectorizer\n",
    "corpus = []\n",
    "with open(train_file,'r', encoding=\"utf-8\") as fr:\n",
    "    lines = fr.readlines()\n",
    "    for line in lines:\n",
    "        row = line.split('\\t')\n",
    "        if row[0] == 'ID':\n",
    "            continue\n",
    "        tweet = row[1].lower()\n",
    "        corpus.append(tweet)\n",
    "with open(test_file,'r', encoding=\"utf-8\") as fr:\n",
    "    lines = fr.readlines()\n",
    "    for line in lines:\n",
    "        row = line.split('\\t')\n",
    "        if row[0] == 'ID':\n",
    "            continue\n",
    "        tweet = row[1].lower()\n",
    "        corpus.append(tweet)\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "X = X.todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train data feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train Feature Extraction\n",
    "train_ph1 = []\n",
    "train_ph2 = []\n",
    "i = 0\n",
    "with open(train_file,'r', encoding=\"utf-8\") as fr:\n",
    "    lines = fr.readlines()\n",
    "    for line in lines:\n",
    "        feature_vector_1 = []\n",
    "        feature_vector_2 = []\n",
    "        row = line.split('\\t')\n",
    "        if row[0] == 'ID':\n",
    "            continue\n",
    "        tweet = row[1].lower()\n",
    "        \n",
    "        #First phase features\n",
    "        feature_vector_1.append(mpqa_subj(tweet))\n",
    "        feature_vector_1.append(pot_adj(tweet))\n",
    "        feature_vector_1.extend(X[i].tolist()[0])\n",
    "\n",
    "        #Second Phase features\n",
    "        senti = sentiword_mpqa_sentiment(tweet)\n",
    "        feature_vector_2.extend(senti)\n",
    "        feature_vector_2.extend(X[i].tolist()[0])\n",
    "        i+=1\n",
    "        category = row[2].rstrip()\n",
    "        if category == 'neutral':\n",
    "            feature_vector_1.append(1)\n",
    "            train_ph1.append(feature_vector_1)\n",
    "        else:\n",
    "            feature_vector_1.append(0)\n",
    "            train_ph1.append(feature_vector_1)\n",
    "            if category == 'negative':\n",
    "                feature_vector_2.append(0)\n",
    "                train_ph2.append(feature_vector_2)\n",
    "            else:\n",
    "                feature_vector_2.append(1)\n",
    "                train_ph2.append(feature_vector_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test data feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the test data and calculate features\n",
    "test = []\n",
    "test_y = []\n",
    "with open(test_file,'r', encoding=\"utf-8\") as fr:\n",
    "    lines = fr.readlines()\n",
    "    for line in lines:\n",
    "        feature_vector_1 = []\n",
    "        feature_vector_2 = []\n",
    "        row = line.split('\\t')\n",
    "        if row[0] == 'ID':\n",
    "            continue\n",
    "        tweet = row[1].lower()\n",
    "        target = \"\"\n",
    "\n",
    "        #First phase features\n",
    "        feature_vector_1.append(mpqa_subj(tweet))\n",
    "        feature_vector_1.append(pot_adj(tweet))\n",
    "        feature_vector_1.extend(X[i].tolist()[0])\n",
    "\n",
    "        #Second Phase features\n",
    "        senti = sentiword_mpqa_sentiment(tweet)\n",
    "        feature_vector_2.extend(senti)\n",
    "        feature_vector_2.extend(X[i].tolist()[0])\n",
    "        i+=1 \n",
    "        test.append((np.array(feature_vector_1,dtype=np.int32),np.array(feature_vector_2,dtype=np.int32)))\n",
    "        category = row[2].rstrip()\n",
    "        if category == 'neutral':\n",
    "            test_y.append(2)\n",
    "        else:\n",
    "            if category == 'negative':\n",
    "                test_y.append(1)\n",
    "            else:\n",
    "                test_y.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15130, 54176)\n",
      "(9492, 54176)\n",
      "(1868,)\n"
     ]
    }
   ],
   "source": [
    "train_ph1 = np.array(train_ph1, dtype = np.int32)\n",
    "train_ph2 = np.array(train_ph2,dtype = np.int32)\n",
    "test_y = np.array(test_y,dtype = np.int32)\n",
    "print(train_ph1.shape)\n",
    "print(train_ph2.shape)\n",
    "print(test_y.shape)\n",
    "data_key = (train_ph1,train_ph2,test,test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC done\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] C=1.0023052380778996, dual=False ................................\n",
      "[LibLinear][CV] .... C=1.0023052380778996, dual=False, score=0.628, total=  13.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   13.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] C=1.0023052380778996, dual=False ................................\n",
      "[LibLinear][CV] .... C=1.0023052380778996, dual=False, score=0.622, total=  10.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   23.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] C=1.0023052380778996, dual=False ................................\n",
      "[LibLinear][CV] .... C=1.0023052380778996, dual=False, score=0.629, total=  10.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   34.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] C=3.6011768069240193, dual=False ................................\n",
      "[LibLinear][CV] .... C=3.6011768069240193, dual=False, score=0.626, total=  13.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   49.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] C=3.6011768069240193, dual=False ................................\n",
      "[LibLinear][CV] .... C=3.6011768069240193, dual=False, score=0.620, total=  13.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  1.1min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] C=3.6011768069240193, dual=False ................................\n",
      "[LibLinear][CV] .... C=3.6011768069240193, dual=False, score=0.628, total=  12.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:  1.3min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] C=12.938647731300748, dual=False ................................\n",
      "[LibLinear][CV] .... C=12.938647731300748, dual=False, score=0.623, total=  20.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:  1.6min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] C=12.938647731300748, dual=False ................................\n",
      "[LibLinear][CV] .... C=12.938647731300748, dual=False, score=0.615, total=  22.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:  2.0min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] C=12.938647731300748, dual=False ................................\n",
      "[LibLinear][CV] .... C=12.938647731300748, dual=False, score=0.623, total=  19.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:  2.3min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] C=46.487194073008524, dual=False ................................\n",
      "[LibLinear][CV] .... C=46.487194073008524, dual=False, score=0.622, total=  22.3s\n",
      "[CV] C=46.487194073008524, dual=False ................................\n",
      "[LibLinear][CV] .... C=46.487194073008524, dual=False, score=0.614, total=  26.2s\n",
      "[CV] C=46.487194073008524, dual=False ................................\n",
      "[LibLinear][CV] .... C=46.487194073008524, dual=False, score=0.622, total=  37.0s\n",
      "[CV] C=167.02357600737488, dual=False ................................\n",
      "[LibLinear][CV] .... C=167.02357600737488, dual=False, score=0.624, total=  10.4s\n",
      "[CV] C=167.02357600737488, dual=False ................................\n",
      "[LibLinear][CV] .... C=167.02357600737488, dual=False, score=0.614, total=  11.2s\n",
      "[CV] C=167.02357600737488, dual=False ................................\n",
      "[LibLinear][CV] .... C=167.02357600737488, dual=False, score=0.623, total=  29.1s\n",
      "[CV] C=600.0980592306573, dual=False .................................\n",
      "[LibLinear][CV] ..... C=600.0980592306573, dual=False, score=0.625, total=   9.6s\n",
      "[CV] C=600.0980592306573, dual=False .................................\n",
      "[LibLinear][CV] ..... C=600.0980592306573, dual=False, score=0.617, total=   9.5s\n",
      "[CV] C=600.0980592306573, dual=False .................................\n",
      "[LibLinear][CV] ..... C=600.0980592306573, dual=False, score=0.623, total=  22.1s\n",
      "[CV] C=2156.088914516479, dual=False .................................\n",
      "[LibLinear][CV] ..... C=2156.088914516479, dual=False, score=0.625, total=   9.4s\n",
      "[CV] C=2156.088914516479, dual=False .................................\n",
      "[LibLinear][CV] ..... C=2156.088914516479, dual=False, score=0.618, total=   9.7s\n",
      "[CV] C=2156.088914516479, dual=False .................................\n",
      "[LibLinear][CV] ..... C=2156.088914516479, dual=False, score=0.621, total=  28.2s\n",
      "[CV] C=7746.599636167191, dual=False .................................\n",
      "[LibLinear][CV] ..... C=7746.599636167191, dual=False, score=0.624, total=   9.2s\n",
      "[CV] C=7746.599636167191, dual=False .................................\n",
      "[LibLinear][CV] ..... C=7746.599636167191, dual=False, score=0.617, total=   9.4s\n",
      "[CV] C=7746.599636167191, dual=False .................................\n",
      "[LibLinear][CV] ..... C=7746.599636167191, dual=False, score=0.621, total=  26.1s\n",
      "[CV] C=27832.713910373885, dual=False ................................\n",
      "[LibLinear][CV] .... C=27832.713910373885, dual=False, score=0.624, total=   9.6s\n",
      "[CV] C=27832.713910373885, dual=False ................................\n",
      "[LibLinear][CV] .... C=27832.713910373885, dual=False, score=0.617, total=   9.5s\n",
      "[CV] C=27832.713910373885, dual=False ................................\n",
      "[LibLinear][CV] .... C=27832.713910373885, dual=False, score=0.621, total=  24.7s\n",
      "[CV] C=100000.0, dual=False ..........................................\n",
      "[LibLinear][CV] .............. C=100000.0, dual=False, score=0.625, total=   9.9s\n",
      "[CV] C=100000.0, dual=False ..........................................\n",
      "[LibLinear][CV] .............. C=100000.0, dual=False, score=0.618, total=  10.1s\n",
      "[CV] C=100000.0, dual=False ..........................................\n",
      "[LibLinear][CV] .............. C=100000.0, dual=False, score=0.621, total=  22.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:  8.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Phase 1 done\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] C=1.0023052380778996, dual=False ................................\n",
      "[LibLinear][CV] .... C=1.0023052380778996, dual=False, score=0.837, total=   7.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    7.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] C=1.0023052380778996, dual=False ................................\n",
      "[LibLinear][CV] .... C=1.0023052380778996, dual=False, score=0.827, total=   6.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   14.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] C=1.0023052380778996, dual=False ................................\n",
      "[LibLinear][CV] .... C=1.0023052380778996, dual=False, score=0.841, total=   6.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   20.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] C=3.6011768069240193, dual=False ................................\n",
      "[LibLinear][CV] .... C=3.6011768069240193, dual=False, score=0.836, total=   6.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   27.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] C=3.6011768069240193, dual=False ................................\n",
      "[LibLinear][CV] .... C=3.6011768069240193, dual=False, score=0.823, total=   7.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   34.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] C=3.6011768069240193, dual=False ................................\n",
      "[LibLinear][CV] .... C=3.6011768069240193, dual=False, score=0.839, total=   6.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:   41.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] C=12.938647731300748, dual=False ................................\n",
      "[LibLinear][CV] .... C=12.938647731300748, dual=False, score=0.837, total=   7.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:   49.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] C=12.938647731300748, dual=False ................................\n",
      "[LibLinear][CV] .... C=12.938647731300748, dual=False, score=0.823, total=   6.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:   56.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] C=12.938647731300748, dual=False ................................\n",
      "[LibLinear][CV] .... C=12.938647731300748, dual=False, score=0.840, total=   6.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:  1.1min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] C=46.487194073008524, dual=False ................................\n",
      "[LibLinear][CV] .... C=46.487194073008524, dual=False, score=0.836, total=   6.0s\n",
      "[CV] C=46.487194073008524, dual=False ................................\n",
      "[LibLinear][CV] .... C=46.487194073008524, dual=False, score=0.823, total=   6.1s\n",
      "[CV] C=46.487194073008524, dual=False ................................\n",
      "[LibLinear][CV] .... C=46.487194073008524, dual=False, score=0.840, total=   6.1s\n",
      "[CV] C=167.02357600737488, dual=False ................................\n",
      "[LibLinear][CV] .... C=167.02357600737488, dual=False, score=0.837, total=   5.8s\n",
      "[CV] C=167.02357600737488, dual=False ................................\n",
      "[LibLinear][CV] .... C=167.02357600737488, dual=False, score=0.822, total=   6.0s\n",
      "[CV] C=167.02357600737488, dual=False ................................\n",
      "[LibLinear][CV] .... C=167.02357600737488, dual=False, score=0.840, total=   5.8s\n",
      "[CV] C=600.0980592306573, dual=False .................................\n",
      "[LibLinear][CV] ..... C=600.0980592306573, dual=False, score=0.838, total=   5.9s\n",
      "[CV] C=600.0980592306573, dual=False .................................\n",
      "[LibLinear][CV] ..... C=600.0980592306573, dual=False, score=0.822, total=   5.9s\n",
      "[CV] C=600.0980592306573, dual=False .................................\n",
      "[LibLinear][CV] ..... C=600.0980592306573, dual=False, score=0.840, total=   5.8s\n",
      "[CV] C=2156.088914516479, dual=False .................................\n",
      "[LibLinear][CV] ..... C=2156.088914516479, dual=False, score=0.838, total=   5.9s\n",
      "[CV] C=2156.088914516479, dual=False .................................\n",
      "[LibLinear][CV] ..... C=2156.088914516479, dual=False, score=0.821, total=   5.8s\n",
      "[CV] C=2156.088914516479, dual=False .................................\n",
      "[LibLinear][CV] ..... C=2156.088914516479, dual=False, score=0.840, total=   6.1s\n",
      "[CV] C=7746.599636167191, dual=False .................................\n",
      "[LibLinear][CV] ..... C=7746.599636167191, dual=False, score=0.838, total=   5.9s\n",
      "[CV] C=7746.599636167191, dual=False .................................\n",
      "[LibLinear][CV] ..... C=7746.599636167191, dual=False, score=0.821, total=   5.8s\n",
      "[CV] C=7746.599636167191, dual=False .................................\n",
      "[LibLinear][CV] ..... C=7746.599636167191, dual=False, score=0.840, total=   6.6s\n",
      "[CV] C=27832.713910373885, dual=False ................................\n",
      "[LibLinear][CV] .... C=27832.713910373885, dual=False, score=0.837, total=   5.8s\n",
      "[CV] C=27832.713910373885, dual=False ................................\n",
      "[LibLinear][CV] .... C=27832.713910373885, dual=False, score=0.821, total=   5.9s\n",
      "[CV] C=27832.713910373885, dual=False ................................\n",
      "[LibLinear][CV] .... C=27832.713910373885, dual=False, score=0.840, total=   5.9s\n",
      "[CV] C=100000.0, dual=False ..........................................\n",
      "[LibLinear][CV] .............. C=100000.0, dual=False, score=0.837, total=   5.7s\n",
      "[CV] C=100000.0, dual=False ..........................................\n",
      "[LibLinear][CV] .............. C=100000.0, dual=False, score=0.821, total=   5.7s\n",
      "[CV] C=100000.0, dual=False ..........................................\n",
      "[LibLinear][CV] .............. C=100000.0, dual=False, score=0.840, total=   5.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:  3.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Phase 2 done\n"
     ]
    }
   ],
   "source": [
    "parameters = {\n",
    "    'C' : np.logspace(start = 0.001,stop = 5,num = 10),\n",
    "    'dual' : [False]\n",
    "}\n",
    "tot = np.array([[0,0,0],[0,0,0]])\n",
    "# print(data)\n",
    "\n",
    "train_ph1 = shuffle(data_key[0])\n",
    "train_ph2 =shuffle(data_key[1])\n",
    "test = data_key[2]\n",
    "test_y = data_key[3]\n",
    "\n",
    "#Phase 1 Training\n",
    "train_ph1_x = train_ph1[:,:-1]\n",
    "train_ph1_y = train_ph1[:,-1]\n",
    "svc = LinearSVC(max_iter = 100000, verbose=10)\n",
    "print(\"SVC done\")\n",
    "clf1  = GridSearchCV(svc, parameters, cv=3, verbose=10) # Applying Grid Search\n",
    "clf1.fit(train_ph1_x,train_ph1_y)\n",
    "print(\"Phase 1 done\")\n",
    "#Phase 2 Training\n",
    "train_ph2_x = train_ph2[:,:-1]\n",
    "train_ph2_y = train_ph2[:,-1]\n",
    "clf2 = GridSearchCV(svc, parameters, cv=3, verbose=10) # Applying Grid Search\n",
    "waste= clf2.fit(train_ph2_x,train_ph2_y)\n",
    "print(\"Phase 2 done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "for x in test:\n",
    "    preds.append(predict(clf1,clf2,x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t   Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.53      0.58      0.55       582\n",
      "    Positive       0.55      0.59      0.57       532\n",
      "     Neutral       0.50      0.44      0.47       754\n",
      "\n",
      "    accuracy                           0.53      1868\n",
      "   macro avg       0.53      0.54      0.53      1868\n",
      "weighted avg       0.53      0.53      0.53      1868\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\t\\t   Classification Report\\n\")\n",
    "print(classification_report(test_y,preds, target_names=[\"Negative\", \"Positive\", \"Neutral\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
